// ai-toolbox/server/src/tests

// tests/aiFunctions.test.js
const { analyzeCodeSnippet } = require('../utils/aiFunctions');

test('Analyze Code Snippet', async () => {
  const codeSnippet = `
    function multiply(a, b) {
      return a * b;
    }
    module.exports = multiply;
  `;
  const analysis = await analyzeCodeSnippet(codeSnippet);
  expect(analysis).toContain('This is a simple Node.js module which exports a function named `multiply`');
}, 15000); // Increase timeout to 15000 ms
// tests/analyzeCodeQuality.test.js
const { analyzeCodeQuality } = require('../utils/analyzeCodeQuality');
const fs = require('fs');

test('Analyze Code Quality', async () => {
  const path = require('path');
  const projectRoot = path.resolve(__dirname, '..');
  const readmeFilePath = path.join(projectRoot, 'testDir/sampleCode.js');

  const result = await analyzeCodeQuality(readmeFilePath);
  expect(result).toContain('Sample Code');
}, 10000); // Increased timeout to 10000 ms// tests/analyzeState.test.js
const { analyzeState } = require('../utils/analyzeState');
const path = require('path');

test('should analyze project state and return report', () => {
  const projectRoot = path.resolve(__dirname, '..');
  const stateReport = analyzeState(projectRoot);
  expect(stateReport).toHaveProperty('files');
  expect(stateReport).toHaveProperty('directories');
});
// tests/checkDependencies.test.js
const { checkDependencies } = require('../utils/checkDependencies');

test('Check Dependencies', () => {
  const result = checkDependencies();
  expect(result).toContain('Some dependencies are outdated');
});
// tests/codeAnalyzer.test.js
const { analyzeCode } = require('../utils/codeAnalyzer');

const fs = require('fs');

test('analyzeCode should return analysis', async () => {
  const path = require('path');
  // Define paths relative to the script's location
  const projectRoot = path.resolve(__dirname, '..');
  const readmeFilePath = path.join(projectRoot, 'testDir/sampleCode.js');
  const analysis = await analyzeCode(readmeFilePath);
  expect(analysis).toContain('Sample Code');
});

// tests/commandLogger.test.js
const fs = require('fs');
const path = require('path');
const { logCommand } = require('../utils/commandLogger');

describe('Command Logger', () => {
  const logPath = path.join(__dirname, '../command_log.txt');
  beforeAll(() => {
    if (!fs.existsSync(logPath)) {
      fs.writeFileSync(logPath, '', 'utf8');
    }
  });

  it('should log a command with a timestamp', () => {
    const command = 'git commit';
    logCommand(command);
    const logContents = fs.readFileSync(logPath, 'utf-8');
    expect(logContents).toContain(command);
  });
});
// tests/dependencyVerifier.test.js
const { verifyDependencies } = require('../utils/dependencyVerifier');
jest.mock('child_process', () => ({
  exec: jest.fn((cmd, callback) => callback(null, 'mocked output'))
}));

describe('Dependency Verifier', () => {
  it('should verify dependencies', async () => {
    const result = await verifyDependencies();
    expect(result).toEqual({
      "archiver": "^7.0.1",
      "dotenv": "^16.4.5",
      "openai": "^4.52.5",
      "postcss": "^8.4.39",
      "progress-stream": "^2.0.0",
      "react": "^17.0.2",
      "react-dom": "^17.0.2",
      "react-scripts": "^5.0.1"
    });
  });
});
// tests/directoryTraversal.test.js
const path = require('path');
const directoryTraversal = require('../utils/directoryTraversal');

test('should list all files in the directory', done => {
  const files = [];
  const expectedFileCount = 1; // Adjust based on actual file count in testDir
  const projectRoot = path.resolve(__dirname, '..');
  const expectedFilePath = path.join(projectRoot, 'testDir/sampleCode.js').replace(/\\/g, '/');

  directoryTraversal(path.join(projectRoot, 'testDir'), (err, filePath) => {
    if (err) return done(err);
    files.push(filePath.replace(/\\/g, '/'));
    if (files.length === expectedFileCount) {
      expect(files).toContain(expectedFilePath);
      done();
    }
  });
}, 80000); // Increase timeout if necessary
// File: scripts/generate-config.test.js
const fs = require('fs');
const path = require('path');
const { generateConfig } = require('../utils/generate-config');

describe('generateConfig', () => {
  const configPath = path.join(__dirname, '..', 'config/config.json');

  beforeAll(() => {
    if (fs.existsSync(configPath)) fs.unlinkSync(configPath); // Ensure file starts empty
  });

  it('should create a config file', () => {
    generateConfig();
    const configContent = fs.readFileSync(configPath, 'utf-8');
    expect(configContent).toContain('"projectName": "ai-toolbox"');
    expect(configContent).toContain('"version": "1.0.0"');
  });
});
// File: scripts/generate-state-report.test.js
const { generateStateReport } = require('../utils/generate-state-report');
const fs = require('fs');
const path = require('path');

test('generateStateReport creates a project state report', () => {
  const reportPath = path.join(__dirname, '..', 'project-state.json');
  if (fs.existsSync(reportPath)) fs.unlinkSync(reportPath); // Ensure file starts empty

  generateStateReport();

  const reportContent = fs.readFileSync(reportPath, 'utf-8');
  expect(reportContent).toContain('"timestamp"');
});
// tests/generateProjectStructure.test.js
const { generateProjectStructure } = require('../utils/generateProjectStructure');

describe('generateProjectStructure', () => {
  test('should generate project structure excluding node_modules and package-lock.json', () => {
    const structure = generateProjectStructure(process.cwd());
    expect(structure).not.toContain('node_modules');
    expect(structure).not.toContain('package-lock.json');
    expect(structure).toContain('package.json');
  });
});
// tests/gptHelper.test.js
const { gptAnalyzeCode } = require('../utils/gptHelper');

test('gptAnalyzeCode should return valid code snippet', async () => {
  const code = await gptAnalyzeCode('Create a React class component');
  expect(code).toContain('class ExampleComponent extends React.Component');
}, 10000); // Increase timeout to 10000 ms

// File: tests/sum.test.js
// Purpose: Unit test for sum function
// Description: This test checks if the sum function correctly adds two numbers.

const sum = require('../src/sum');

test('adds 1 + 2 to equal 3', () => {
  expect(sum(1, 2)).toBe(3);
});
// File: utils/validateProject.test.js
const fs = require('fs');
const path = require('path');
const { execSync } = require('child_process');
const { logCommand } = require('../utils/commandLogger');
const { validateProject } = require('../utils/validateProject');

describe('Project Validation', () => {
  const logPath = path.join(__dirname, '../command_log.txt');
  const tempDir = path.join(__dirname, '../temp_dir');

  beforeAll(() => {
    if (fs.existsSync(logPath)) {
      fs.unlinkSync(logPath);
    }
    if (!fs.existsSync(tempDir)) {
      fs.mkdirSync(tempDir);
    }
    process.chdir(tempDir);
  });

  afterAll(() => {
    process.chdir(__dirname);
    fs.rmdirSync(tempDir, { recursive: true });
  });

  it('should validate the project by executing logged commands', () => {
    logCommand('npm init -y');
    logCommand('npm install jest');

    validateProject();

    const packageJsonPath = path.join(tempDir, 'package.json');
    const nodeModulesPath = path.join(tempDir, 'node_modules');

    expect(fs.existsSync(packageJsonPath)).toBe(true);
    expect(fs.existsSync(nodeModulesPath)).toBe(true);
  });
});
// tests/verifyProjectStructure.test.js
const { verifyStructure } = require('../utils/verifyProjectStructure');

test('Verify Project Structure', () => {
  const result = verifyStructure();
  expect(result).toBe('Project structure is correct');
});
// tests/virtualAssistant.test.js
const { virtualAssistant } = require('../utils/virtualAssistant');

test('should analyze all code files and suggest fixes', async () => {
  const results = await virtualAssistant();
  expect(results).not.toBeNull();
  results.forEach(result => {
    expect(result).toHaveProperty('file');
    expect(result).toHaveProperty('analysis');
  });
}, 15000); // Increase timeout to 15 seconds


// ai-toolbox/server/src/utils

// utils/aiFunctions.js
const { gptAnalyzeCode } = require('./gptHelper');

async function analyzeCodeSnippet(codeSnippet) {
  try {
    const analysis = await gptAnalyzeCode(codeSnippet);
    console.log('Code Analysis:', analysis);
    return analysis;
  } catch (error) {
    console.error('Error analyzing code snippet:', error);
    throw error;
  }
}

module.exports = { analyzeCodeSnippet };
// utils/analyzeCodeQuality.js
const { gptAnalyzeCode } = require('./gptHelper');
const fs = require('fs');

async function analyzeCodeQuality(filePath) {
  try {
    const code = fs.readFileSync(filePath, 'utf-8');
    const analysis = await gptAnalyzeCode(code);
    return analysis;
  } catch (error) {
    return `Error analyzing code quality: ${error.message}`;
  }
}

module.exports = { analyzeCodeQuality };
// File: utils/stateAnalyzer.js
// Purpose: Analyze project state and generate a report
// Description: This script scans the project directories and files, then generates a state report.

// utils/analyzeState.js
const fs = require('fs');
const path = require('path');

function analyzeState(directory) {
  const state = {
    files: [],
    directories: []
  };

  function traverse(dir) {
    const items = fs.readdirSync(dir);
    items.forEach(item => {
      const fullPath = path.join(dir, item);
      const stats = fs.statSync(fullPath);
      if (stats.isDirectory()) {
        state.directories.push(fullPath);
        traverse(fullPath);
      } else {
        state.files.push(fullPath);
      }
    });
  }

  traverse(directory);
  return state;
}

module.exports = { analyzeState };
// utils/backUpProjectFiles.js
/**
 * Compress the entire project directory.
 * Provide real-time updates on the compression progress.
 * Log errors and progress messages.
 * @param {string} directory - The root directory to verify.
 * @returns {string} - Result of the verification.
 */
const fs = require('fs');
const path = require('path');
const archiver = require('archiver');
const progress = require('progress-stream');

const dirName = 'docs'; // Only change the dirName var. Use '../' if you're going to back up the project root directory.

const zipDir = `../${dirName}`; // Which directory would you like to zip? Use -> '../' <- for root directory. 
const backUpDir = '../.backup-project-files'; // Which folder you're zipping the files into 
const zipName = dirName; // Name of the zip file tests.zip

// Paths
const projectDirectory = path.resolve(__dirname, zipDir); // (__dirname, '../') for root directory. Resolve project directory relative to script location
const backupDirectory = path.resolve(projectDirectory, backUpDir); // Replace with your backup path
console.log(projectDirectory);
console.log(backupDirectory);


// Ensure the backup directory exists
if (!fs.existsSync(backupDirectory)) {
    fs.mkdirSync(backupDirectory, { recursive: true });
}

// Function to generate a unique backup filename
const getUniqueBackupFileName = (baseName) => {
    let index = 0;
    let backupFile = path.join(backupDirectory, `${baseName}.zip`);
    while (fs.existsSync(backupFile)) {
        index += 1;
        backupFile = path.join(backupDirectory, `${baseName}-${index.toString().padStart(2, '0')}.zip`);
    }
    return backupFile;
};

const backupFile = getUniqueBackupFileName(zipName);

// Create a file to stream archive data to.
const output = fs.createWriteStream(backupFile);
const archive = archiver('zip', {
    zlib: { level: 9 } // Sets the compression level.
});

// Listen for all archive data to be written
output.on('close', () => {
    console.log(`Backup completed: ${archive.pointer()} total bytes`);
});

// This event is fired when the data source is drained no matter what was the data source.
// It is not part of this library but rather from the NodeJS Stream API.
output.on('end', () => {
    console.log('Data has been drained');
});

// Good practice to catch this error explicitly
archive.on('error', (err) => {
    throw err;
});

// Create progress stream
const progressStream = progress({
    length: fs.statSync(projectDirectory).size,
    time: 100 // Update every 100 ms
});

progressStream.on('progress', (progress) => {
    console.log(`Compression progress: ${Math.round(progress.percentage)}% (${(progress.transferred / (1024 * 1024)).toFixed(2)} MB transferred)`);
});

// Pipe the progress stream to the archive
archive.pipe(progressStream).pipe(output);

// Append files from the project directory
archive.directory(projectDirectory, false);

// Finalize the archive (i.e. we are done appending files but streams have to finish yet)
archive.finalize();// utils/checkDependencies.js
const { execSync } = require('child_process');

function checkDependencies() {
  try {
    execSync('npm outdated', { stdio: 'ignore' });
    return 'All dependencies are up-to-date';
  } catch (error) {
    return 'Some dependencies are outdated';
  }
}

module.exports = { checkDependencies };
// utils/codeAnalyzer.js
const fs = require('fs');
const { gptConnect } = require('./gptConnect');

async function analyzeCode(filePath) {
  const code = fs.readFileSync(filePath, 'utf-8');
  const response = await gptConnect.chat.completions.create({
    model: 'gpt-3.5-turbo',
    messages: [{ role: 'user', content: code }],
  });
  return response.choices[0].message.content;
}

module.exports = { analyzeCode };// File: utils/commandLogger.js
// Purpose: Log commands executed in the project
// Description: This utility captures and formats command logs with timestamps.

const fs = require('fs');
const path = require('path');

// Define paths relative to the script's location
const projectRoot = path.resolve(__dirname, '..');

function logCommand(command) {
  const logPath = path.join(projectRoot, 'command_log.txt');
  const timestamp = new Date().toISOString();
  fs.appendFileSync(logPath, `${timestamp}: ${command}\n`);
}

module.exports = { logCommand };
// utils/dependencyVerifier.js

// const { exec } = require('child_process');
const fs = require('fs');
const path = require('path');

function verifyDependencies() {
  const packageJsonPath = path.join(__dirname, '../package.json');
  if (!fs.existsSync(packageJsonPath)) {
    throw new Error('package.json not found');
  }

  const packageJson = require(packageJsonPath);
  const dependencies = packageJson.dependencies;
  // Add logic to verify dependencies
  return dependencies;
}

module.exports = { verifyDependencies };
// utils/directoryTraversal.js
const fs = require('fs');
const path = require('path');

function directoryTraversal(dir, callback) {
  fs.readdir(dir, (err, files) => {
    if (err) return callback(err);
    files.forEach(file => {
      const filePath = path.join(dir, file);
      fs.stat(filePath, (err, stat) => {
        if (err) return callback(err);
        if (stat.isDirectory()) {
          directoryTraversal(filePath, callback);
        } else {
          callback(null, filePath);
        }
      });
    });
  });
}

module.exports = directoryTraversal;// utils/validate.js
const { execSync } = require('child_process');
const path = require('path');

const projectRoot = path.resolve(__dirname, '..');

try {
    const eslintConfigPath = path.join(projectRoot, 'eslint.config.mjs');
    const rootDir = path.join(projectRoot, '**/*.js');
    const scriptsPath = path.join(projectRoot, 'scripts/*.js');
    const utilsPath = path.join(projectRoot, 'utils/*.js');

    const command = `npx eslint --config "${eslintConfigPath}" "${rootDir.replace(/\\/g, "/")}" "${scriptsPath.replace(/\\/g, "/")}" "${utilsPath.replace(/\\/g, "/")}"`;

    console.log(`ESLint Config Path: ${eslintConfigPath}`);
    console.log(`Root Path: ${rootDir}`);
    console.log(`Scripts Path: ${scriptsPath}`);
    console.log(`Utils Path: ${utilsPath}`);
    console.log(`Executing Command: ${command}`);

    execSync(command, { stdio: 'inherit' });
    console.log('ESLint validation completed successfully.');
} catch (error) {
    console.error('Error running ESLint:', error.message);
    process.exit(1);
}
// File: scripts/generate-config.js
// Purpose: Generate configuration files for the project
// Description: This script will create initial configuration files needed for the project setup.

const fs = require('fs');
const path = require('path');

// Define paths relative to the script's location
const projectRoot = path.resolve(__dirname, '..');
const configPath = path.join(projectRoot, 'config/config.json');

const configContent = {
  projectName: "ai-toolbox",
  version: "1.0.0"
};

function generateConfig() {
  fs.writeFileSync(configPath, JSON.stringify(configContent, null, 2));
  console.log('Configuration file generated at config/config.json');
}

module.exports = { generateConfig };
// File: scripts/generate-state-report.js
// Purpose: Analyze project state and generate a report
// Description: This script scans the project directories and files, then generates a state report containing the current status and changes in the project.

const fs = require('fs');
const path = require('path');

/**
 * Recursively scan a directory and list all files.
 * @param {string} dir - Directory to scan.
 * @returns {string[]} List of file paths.
 */
function getFiles(dir) {
  let results = [];
  const list = fs.readdirSync(dir);

  list.forEach(file => {
    file = path.resolve(dir, file);
    const stat = fs.statSync(file);
    if (stat && stat.isDirectory()) {
      results = results.concat(getFiles(file));
    } else {
      results.push(file);
    }
  });

  return results;
}

/**
 * Generate a project state report.
 */
function generateStateReport() {
  const report = {
    timestamp: new Date().toISOString(),
    // other report details
  };

  const reportPath = path.resolve(__dirname, '../project-state.json');
  fs.writeFileSync(reportPath, JSON.stringify(report, null, 2));
  console.log(`Project state report generated at ${reportPath}`);
}

module.exports = { generateStateReport };// utils/generateProjectStructure.js
// Purpose: Generate the project structure.
const fs = require('fs');
const path = require('path');

function generateProjectStructure(dir) {
  const files = fs.readdirSync(dir).filter(file => !['node_modules', 'package-lock.json'].includes(file));
  return files;
}

module.exports = { generateProjectStructure };
// utils/gptConnect.js
// require('dotenv').config();
// const { OpenAI } = require('openai');

// const openai = new OpenAI({
//     apiKey: process.env.OPENAI_API_KEY
// });

// module.exports = { openai };

// utils/gptConnect.js
// const fs = require('fs');
import 'openai/shims/node'; // Add this line 
require('dotenv').config();
const { OpenAI } = require('openai');

const gptConnect = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
  dangerouslyAllowBrowser: true
});

module.exports = { gptConnect };
// utils/gptHelper.js
/**
 * Analyzes the given code snippet using OpenAI's GPT-4 model.
 * 
 * @param {string} code - The code snippet to analyze.
 * @returns {Promise<string>} - The analysis result from GPT-4.
 */
const fs = require('fs');
const { gptConnect } = require('./gptConnect');

async function gptAnalyzeCode(code) {
  try {
    const response = await gptConnect.chat.completions.create({
      model: "gpt-4",
      messages: [
        {
          role: "system",
          content: "You are a helpful assistant that analyzes code."
        },
        {
          role: "user",
          content: `Analyze this code:\n\n${code}`
        }
      ],
      max_tokens: 150
    });
    return response.choices[0].message.content.trim();
  } catch (error) {
    console.error('Error analyzing code:', error);
    throw error;
  }
}

module.exports = { gptAnalyzeCode };
// File: utils/nextStep.js
// Purpose: Generate next steps using GPT
// Description: This script generates the next steps for the project based on the current state and history.

const { generateProjectPlan } = require('./gptHelper');

async function nextStep() {
  const plan = await generateProjectPlan('Generate next steps for my project...');
  console.log(plan);
}

nextStep();
// utils/projectVerifier.js
const fs = require('fs');
const path = require('path');
const exec = require('child_process').exec;
const { gptAnalyzeCode } = require('./gptHelper');

function verifyProjectStructure() {
  const expectedStructure = [
    'package.json',
    'jest.config.js',
    'src/',
    'tests/',
    'utils/',
  ];

  expectedStructure.forEach((item) => {
    if (!fs.existsSync(path.join(__dirname, '..', item))) {
      console.error(`Missing ${item}`);
    } else {
      console.log(`${item} exists`);
    }
  });
}

function verifyDependencies() {
  exec('npm ls', (err, stdout, stderr) => {
    if (err) {
      console.error('Error in verifying dependencies:', stderr);
    } else {
      console.log('Dependencies verified:', stdout);
    }
  });
}

function runTests() {
  exec('npm test', (err, stdout, stderr) => {
    if (err) {
      console.error('Tests failed:', stderr);
    } else {
      console.log('Test results:', stdout);
    }
  });
}

function analyzeCode() {
  const filesToAnalyze = [
    path.join(__dirname, '..', 'src', 'index.js'),
    path.join(__dirname, '..', 'utils', 'commandLogger.js'),
    // Add more files as needed
  ];

  filesToAnalyze.forEach((file) => {
    const code = fs.readFileSync(file, 'utf-8');
    gptAnalyzeCode(code).then((analysis) => {
      console.log(`Analysis for ${file}: ${analysis}`);
    });
  });
}

module.exports = { verifyProjectStructure, verifyDependencies, runTests, analyzeCode };
// File: utils/taskRunner.js
// Purpose: Run automated tasks such as tests
// Description: This script uses child processes to run tasks and logs the results.

const { exec } = require('child_process');

function runTests() {
  exec('npm test', (err, stdout, stderr) => {
    if (err) {
      console.error(`Error: ${stderr}`);
      return;
    }
    console.log(`Results: ${stdout}`);
  });
}

module.exports = { runTests };
// utils/testApiConnection.js
// const { openai } = require('./gptConnect');
const fs = require('fs');
const { gptAnalyzeCode } = require('./gptHelper');

async function testConnection() {
  try {
    const codeSnippet = `
    function add(a, b) {
      return a + b;
    }
    module.exports = add;
    `;
    const analysis = await gptAnalyzeCode(codeSnippet);
    console.log('API Connection Successful:', analysis);
  } catch (error) {
    console.error('API Connection Failed:', error);
  }
}

testConnection();
// File: utils/validateProject.js
// Purpose: Validate project by re-executing logged commands
// Description: This script reads the command log, re-executes commands, and ensures project consistency.

const fs = require('fs');
const path = require('path');
const { execSync } = require('child_process');

// Define paths relative to the script's location
const projectRoot = path.resolve(__dirname, '..');

const LOG_FILE = path.join(projectRoot, 'command_log.txt');
const TEMP_DIR = path.join(projectRoot, 'temp_dir');

if (!fs.existsSync(LOG_FILE)) {
  console.error('command_log.txt not found!');
  process.exit(1);
}

if (!fs.existsSync(TEMP_DIR)) {
  fs.mkdirSync(TEMP_DIR);
}

process.chdir(TEMP_DIR);

const logData = fs.readFileSync(LOG_FILE, 'utf-8');
const logLines = logData.split('\n');

logLines.forEach(line => {
  const commandMatch = line.match(/Command: (.*) \| Outcome:/);
  if (commandMatch) {
    const command = commandMatch[1];
    if (command) {
      console.log(`Executing: ${command}`);
      try {
        execSync(command, { stdio: 'inherit' });
      } catch (error) {
        console.error(`Error executing command: ${command}`);
      }
    }
  }
});

process.chdir(__dirname);
fs.rmSync(TEMP_DIR, { recursive: true, force: true });

console.log('Project validation completed successfully.');
// utils/verifyProjectStructure.js
/**
 * Verifies that the project structure matches the expected layout.
 * 
 * @param {string} directory - The root directory to verify.
 * @returns {string} - Result of the verification.
 */
const fs = require('fs');
const path = require('path');

const expectedStructure = {
  'package.json': 'file',
  'utils': 'directory',
  'tests': 'directory',
  'scripts': 'directory',
  // Add more expected files and directories here
};

function verifyStructure(directory = '.') {
  for (const [name, type] of Object.entries(expectedStructure)) {
    const fullPath = path.join(directory, name);
    if (!fs.existsSync(fullPath)) {
      return `Missing ${type}: ${name}`;
    }
    const stat = fs.statSync(fullPath);
    if ((type === 'file' && !stat.isFile()) || (type === 'directory' && !stat.isDirectory())) {
      return `Expected ${name} to be a ${type}, but it's not`;
    }
  }
  return 'Project structure is correct';
}

module.exports = { verifyStructure };
// utils/virtualAssistant.js
// const { traverseDirectory } = require('./directoryTraversal');
// const { verifyDependencies } = require('./dependencyVerifier');
// const { analyzeCode } = require('./codeAnalyzer');
// const { analyzeCodeQuality } = require('./analyzeCodeQuality');
// const fs = require('fs');
// const path = require('path');
// utils/virtualAssistant.js
const { analyzeCode } = require('./codeAnalyzer');
const fs = require('fs');
const path = require('path');
const gptConnect = require('./gptConnect');

async function virtualAssistant() {
  try {
    const dirPath = path.resolve(__dirname, '../testDir');
    const files = fs.readdirSync(dirPath).filter(file => file.endsWith('.js'));
    const results = await Promise.all(files.map(file => analyzeCode(path.join(dirPath, file))));
    return results.map((analysis, index) => ({ file: files[index], analysis }));
  } catch (error) {
    console.error('Error in Virtual Assistant:', error);
    return null;
  }
}

module.exports = { virtualAssistant };





// async function virtualAssistant() {
//   try {
//     const projectRoot = path.resolve(__dirname, '..');
//     const utilsPath = path.join(projectRoot, 'utils');
//     const testsPath = path.join(projectRoot, 'tests');
//     const scriptsPath = path.join(projectRoot, 'scripts');
    
//     const files = [
//       ...fs.readdirSync(utilsPath).map(file => path.join(utilsPath, file)),
//       ...fs.readdirSync(testsPath).map(file => path.join(testsPath, file)),
//       ...fs.readdirSync(scriptsPath).map(file => path.join(scriptsPath, file)),
//     ];

//     const results = await Promise.all(files.map(async (file) => {
//       const content = fs.readFileSync(file, 'utf-8');
//       const analysis = await analyzeCodeQuality(file);
//       return { file, analysis };
//     }));

//     return results;
//   } catch (error) {
//     console.error('Error in Virtual Assistant:', error);
//     return null;
//   }
// }

// module.exports = { virtualAssistant };


// async function virtualAssistant() {
//   try {
//     const files = await traverseDirectory(process.cwd());
//     console.log('Files:', files);

//     const depsStatus = await verifyDependencies();
//     console.log('Dependencies Status:', depsStatus);

//     const assessCode = await analyzeCode(files);
//     console.log('Code Assessment:', assessCode);

//     const codeQuality = await analyzeCodeQuality(files);
//     console.log('Code Quality:', codeQuality);

//     return { files, depsStatus, assessCode, codeQuality };
//   } catch (error) {
//     console.error('Error in Virtual Assistant:', error);
//   }
// }

// module.exports = { virtualAssistant };
